{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digits - Classification Using SVM\n",
    "\n",
    "In this notebook, we'll explore the popular MNIST dataset and build an SVM model to classify handwritten digits. <a href='http://yann.lecun.com/exdb/mnist/'>Here is a detailed description of the dataset.</a>\n",
    "\n",
    "This is a part of a kaggle competition - https://www.kaggle.com/c/digit-recognizer.\n",
    "\n",
    "# Objective\n",
    "We will develop a model using Support Vector Machine which should correctly classify the handwritten digits from 0-9 based on the pixel values given as features. Thus, this is a 10-class classification problem. \n",
    "\n",
    "# Data Description\n",
    "For this problem, we use the MNIST data which is a large database of handwritten digits. The 'pixel values' of each digit (image) comprise the features, and the actual number between 0-9 is the label. \n",
    "\n",
    " \n",
    "\n",
    "Since each image is of 28 x 28 pixels, and each pixel forms a feature, there are 784 features. MNIST digit recognition is a well-studied problem in the ML community, and people have trained numerous models (Neural Networks, SVMs, boosted trees etc.) achieving error rates as low as 0.23% (i.e. accuracy = 99.77%, with a convolutional neural network).\n",
    "\n",
    " \n",
    "\n",
    "Before the popularity of neural networks, though, models such as SVMs and boosted trees were the state-of-the-art in such problems.\n",
    "\n",
    "We'll first explore the dataset a bit, prepare it (scale etc.) and then experiment with linear and non-linear SVMs with various hyperparameters.<br>\n",
    "\n",
    "----------\n",
    "We'll divide the analysis into the following parts:\n",
    "- Data understanding and cleaning\n",
    "- Data preparation for model building\n",
    "- Building an SVM model - hyperparameter tuning, model evaluation etc.\n",
    "\n",
    "#### NOTE:\n",
    "Considering the **computational limitations** of the system and the data size at hand, to make our life easier we are going to use 50% of the available data set for model building.<br>\n",
    "\n",
    "Final model can be extended to operate on the complete data set as well, considering appropirate computatinal power is available by the computing machine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding and Cleaning\n",
    " \n",
    " Let's understand the dataset and see if it needs some cleaning etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "digits = pd.read_csv(\"train.csv\")\n",
    "digits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head\n",
    "digits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four = digits.iloc[3, 1:]\n",
    "four.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a26b33208>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a26c7a470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "four = four.values.reshape(28, 28)\n",
    "plt.imshow(four, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side note: Indexing Recall ####\n",
    "`list =    [0, 4, 2, 10, 22, 101, 10]` <br>\n",
    "`indices = [0, 1, 2, 3, ...,        ]` <br>\n",
    "`reverse = [-n           -3  -2   -1]` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 220 179   6   0   0   0   0   0   0   0   0   9  77   0   0   0   0]\n",
      " [  0  28 247  17   0   0   0   0   0   0   0   0  27 202   0   0   0   0]\n",
      " [  0   0 242 155   0   0   0   0   0   0   0   0  27 254  63   0   0   0]\n",
      " [  0   0 160 207   6   0   0   0   0   0   0   0  27 254  65   0   0   0]\n",
      " [  0   0 127 254  21   0   0   0   0   0   0   0  20 239  65   0   0   0]\n",
      " [  0   0  77 254  21   0   0   0   0   0   0   0   0 195  65   0   0   0]\n",
      " [  0   0  70 254  21   0   0   0   0   0   0   0   0 195 142   0   0   0]\n",
      " [  0   0  56 251  21   0   0   0   0   0   0   0   0 195 227   0   0   0]\n",
      " [  0   0   0 222 153   5   0   0   0   0   0   0   0 120 240  13   0   0]\n",
      " [  0   0   0  67 251  40   0   0   0   0   0   0   0  94 255  69   0   0]\n",
      " [  0   0   0   0 234 184   0   0   0   0   0   0   0  19 245  69   0   0]\n",
      " [  0   0   0   0 234 169   0   0   0   0   0   0   0   3 199 182  10   0]\n",
      " [  0   0   0   0 154 205   4   0   0  26  72 128 203 208 254 254 131   0]\n",
      " [  0   0   0   0  61 254 129 113 186 245 251 189  75  56 136 254  73   0]\n",
      " [  0   0   0   0  15 216 233 233 159 104  52   0   0   0  38 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5 206 106   0]]\n"
     ]
    }
   ],
   "source": [
    "# visualise the array\n",
    "print(four[5:-5, 5:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise the counts of 'label' to see how many labels of each digit are present\n",
    "digits.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11.15\n",
       "7    10.48\n",
       "3    10.36\n",
       "9     9.97\n",
       "2     9.95\n",
       "6     9.85\n",
       "0     9.84\n",
       "4     9.70\n",
       "8     9.67\n",
       "5     9.04\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise count in terms of percentage \n",
    "100*(round(digits.label.astype('category').value_counts()/len(digits.index), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, each digit/label has an approximately 9%-11% fraction in the dataset and the **dataset is balanced**. This is an important factor in considering the choices of models to be used, especially SVM, since **SVMs rarely perform well on imbalanced data** (think about why that might be the case).\n",
    "\n",
    "Let's quickly look at missing values, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel0      0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "pixel5      0\n",
       "pixel6      0\n",
       "pixel7      0\n",
       "pixel8      0\n",
       "pixel9      0\n",
       "pixel10     0\n",
       "pixel11     0\n",
       "pixel12     0\n",
       "pixel13     0\n",
       "pixel14     0\n",
       "pixel15     0\n",
       "pixel16     0\n",
       "pixel17     0\n",
       "pixel18     0\n",
       "pixel19     0\n",
       "pixel20     0\n",
       "pixel21     0\n",
       "pixel22     0\n",
       "pixel23     0\n",
       "pixel24     0\n",
       "pixel25     0\n",
       "pixel26     0\n",
       "pixel27     0\n",
       "pixel28     0\n",
       "           ..\n",
       "pixel754    0\n",
       "pixel755    0\n",
       "pixel756    0\n",
       "pixel757    0\n",
       "pixel758    0\n",
       "pixel759    0\n",
       "pixel760    0\n",
       "pixel761    0\n",
       "pixel762    0\n",
       "pixel763    0\n",
       "pixel764    0\n",
       "pixel765    0\n",
       "pixel766    0\n",
       "pixel767    0\n",
       "pixel768    0\n",
       "pixel769    0\n",
       "pixel770    0\n",
       "pixel771    0\n",
       "pixel772    0\n",
       "pixel773    0\n",
       "pixel774    0\n",
       "pixel775    0\n",
       "pixel776    0\n",
       "pixel777    0\n",
       "pixel778    0\n",
       "pixel779    0\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values - there are none\n",
    "digits.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's look at the average values of each column, since we'll need to do some rescaling in case the ranges vary too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8    ...         pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0    ...     42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0    ...         0.219286      0.117095   \n",
       "std        0.0      0.0      0.0    ...         6.312890      4.633819   \n",
       "min        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0    ...         0.000000      0.000000   \n",
       "max        0.0      0.0      0.0    ...       254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average values/distributions of features\n",
    "description = digits.describe()\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the max value of the mean and maximum values of some features (pixels) is 139, 255 etc., whereas most features lie in much lower ranges  (look at description of pixel 0, pixel 1 etc. above).\n",
    "\n",
    "Thus, it seems like a good idea to rescale the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Model Building\n",
    "\n",
    "Let's now prepare the dataset for building the model. We'll only use a fraction of the data else training will take a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 784)\n",
      "(37800, 784)\n",
      "(4200,)\n",
      "(37800,)\n"
     ]
    }
   ],
   "source": [
    "# Creating training and test sets\n",
    "# Splitting the data into train and test\n",
    "X = digits.iloc[:, 1:]\n",
    "Y = digits.iloc[:, 0]\n",
    "\n",
    "# Rescaling the features\n",
    "from sklearn.preprocessing import scale\n",
    "X = scale(X)\n",
    "\n",
    "# train test split with train_size=10% and test size=90%\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.10, random_state=101)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete test set from memory, to avoid a memory error\n",
    "# we'll anyway use CV to evaluate the model, and can use the separate test.csv file as well\n",
    "# to evaluate the model finally\n",
    "\n",
    "# del x_test\n",
    "# del y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Let's now build the model and tune the hyperparameters. Let's start with a **linear model** first.\n",
    "\n",
    "### Linear SVM\n",
    "\n",
    "Let's first try building a linear SVM model (i.e. a linear kernel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# an initial SVM model with linear kernel   \n",
    "svm_linear = svm.SVC(kernel='linear')\n",
    "\n",
    "# fit\n",
    "svm_linear.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 0, 1, 9, 1, 5, 0, 6])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_linear.predict(x_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3615,    0,   12,    8,    8,   28,   28,    5,    9,    2],\n",
       "       [   0, 4089,   16,   23,    9,    3,    3,   13,   25,    4],\n",
       "       [  54,   48, 3363,   64,   74,   13,   53,   52,   59,   10],\n",
       "       [  20,   28,  121, 3387,    8,  175,    5,   54,   58,   44],\n",
       "       [  12,   12,   26,    2, 3399,    7,   41,   41,    4,  158],\n",
       "       [  49,   42,   32,  177,   41, 2899,   54,   14,   82,   28],\n",
       "       [  36,   16,   55,    5,   34,   37, 3486,    3,   21,    0],\n",
       "       [   9,   27,   37,   22,   70,   10,    4, 3619,   14,  142],\n",
       "       [  26,   86,   71,  137,   24,  137,   29,   26, 3096,   33],\n",
       "       [  38,   11,   39,   26,  182,   19,    1,  207,   27, 3228]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation: accuracy\n",
    "# C(i, j) represents the number of points known to be in class i \n",
    "# but predicted to be in class j\n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042592592592592"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measure accuracy\n",
    "metrics.accuracy_score(y_true=y_test, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95      3715\n",
      "          1       0.94      0.98      0.96      4185\n",
      "          2       0.89      0.89      0.89      3790\n",
      "          3       0.88      0.87      0.87      3900\n",
      "          4       0.88      0.92      0.90      3702\n",
      "          5       0.87      0.85      0.86      3418\n",
      "          6       0.94      0.94      0.94      3693\n",
      "          7       0.90      0.92      0.91      3954\n",
      "          8       0.91      0.84      0.88      3665\n",
      "          9       0.88      0.85      0.87      3778\n",
      "\n",
      "avg / total       0.90      0.90      0.90     37800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class-wise accuracy\n",
    "class_wise = metrics.classification_report(y_true=y_test, y_pred=predictions)\n",
    "print(class_wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run gc.collect() (garbage collect) to free up memory\n",
    "# else, since the dataset is large and SVM is computationally heavy,\n",
    "# it'll throw a memory error while training\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linear SVM\n",
    "\n",
    "Let's now try a non-linear model with the RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf kernel with other hyperparameters kept to default \n",
    "svm_rbf = svm.SVC(kernel='rbf')\n",
    "svm_rbf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925582010582\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_rbf.predict(x_test)\n",
    "\n",
    "# accuracy \n",
    "print(metrics.accuracy_score(y_true=y_test, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved with a non-linear kernel is slightly higher than a linear one. Let's now do a grid search CV to tune the hyperparameters C and gamma.\n",
    "\n",
    "### Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct (grid search) cross-validation to find the optimal values \n",
    "# of cost C and the choice of kernel\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':[1, 10, 100], \n",
    "             'gamma': [1e-2, 1e-3, 1e-4]}\n",
    "\n",
    "# instantiate a model \n",
    "svc_grid_search = svm.SVC(kernel=\"rbf\")\n",
    "\n",
    "# create a classifier to perform grid search\n",
    "clf = GridSearchCV(svc_grid_search, param_grid=parameters, scoring='accuracy')\n",
    "\n",
    "# fit\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.323413</td>\n",
       "      <td>3.791693</td>\n",
       "      <td>0.714524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.723450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.712241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336469</td>\n",
       "      <td>0.070002</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.097630</td>\n",
       "      <td>2.630051</td>\n",
       "      <td>0.913095</td>\n",
       "      <td>0.966785</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.919458</td>\n",
       "      <td>0.964962</td>\n",
       "      <td>0.905714</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.914102</td>\n",
       "      <td>0.967892</td>\n",
       "      <td>0.080747</td>\n",
       "      <td>0.036969</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.001298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.384948</td>\n",
       "      <td>3.351721</td>\n",
       "      <td>0.868095</td>\n",
       "      <td>0.891547</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.867427</td>\n",
       "      <td>0.891312</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.872584</td>\n",
       "      <td>0.893329</td>\n",
       "      <td>0.378510</td>\n",
       "      <td>0.060195</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.211799</td>\n",
       "      <td>3.683504</td>\n",
       "      <td>0.734048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.742694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288769</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.528688</td>\n",
       "      <td>2.366703</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937990</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.916249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096395</td>\n",
       "      <td>0.096327</td>\n",
       "      <td>0.010748</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.548124</td>\n",
       "      <td>2.265223</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.959167</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.920171</td>\n",
       "      <td>0.959957</td>\n",
       "      <td>0.906429</td>\n",
       "      <td>0.959286</td>\n",
       "      <td>0.913386</td>\n",
       "      <td>0.958259</td>\n",
       "      <td>0.165654</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.005613</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.676386</td>\n",
       "      <td>3.793287</td>\n",
       "      <td>0.734048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.742694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202933</td>\n",
       "      <td>0.049788</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.634490</td>\n",
       "      <td>2.437732</td>\n",
       "      <td>0.922381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.937277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060910</td>\n",
       "      <td>0.043007</td>\n",
       "      <td>0.010683</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.883860</td>\n",
       "      <td>2.030675</td>\n",
       "      <td>0.909286</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.920884</td>\n",
       "      <td>0.998212</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.997857</td>\n",
       "      <td>0.908375</td>\n",
       "      <td>0.998930</td>\n",
       "      <td>0.198038</td>\n",
       "      <td>0.095490</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0      15.323413         3.791693         0.714524          1.000000       1   \n",
       "1       5.097630         2.630051         0.913095          0.966785       1   \n",
       "2       7.384948         3.351721         0.868095          0.891547       1   \n",
       "3      15.211799         3.683504         0.734048          1.000000      10   \n",
       "4       4.528688         2.366703         0.922857          0.999643      10   \n",
       "5       3.548124         2.265223         0.913333          0.959167      10   \n",
       "6      15.676386         3.793287         0.734048          1.000000     100   \n",
       "7       4.634490         2.437732         0.922381          1.000000     100   \n",
       "8       2.883860         2.030675         0.909286          0.998333     100   \n",
       "\n",
       "  param_gamma                       params  rank_test_score  \\\n",
       "0        0.01      {'C': 1, 'gamma': 0.01}                9   \n",
       "1       0.001     {'C': 1, 'gamma': 0.001}                4   \n",
       "2      0.0001    {'C': 1, 'gamma': 0.0001}                6   \n",
       "3        0.01     {'C': 10, 'gamma': 0.01}                7   \n",
       "4       0.001    {'C': 10, 'gamma': 0.001}                1   \n",
       "5      0.0001   {'C': 10, 'gamma': 0.0001}                3   \n",
       "6        0.01    {'C': 100, 'gamma': 0.01}                7   \n",
       "7       0.001   {'C': 100, 'gamma': 0.001}                2   \n",
       "8      0.0001  {'C': 100, 'gamma': 0.0001}                5   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.723450            1.000000           0.707857   \n",
       "1           0.919458            0.964962           0.905714   \n",
       "2           0.867427            0.891312           0.864286   \n",
       "3           0.742694            1.000000           0.727143   \n",
       "4           0.937990            0.999285           0.914286   \n",
       "5           0.920171            0.959957           0.906429   \n",
       "6           0.742694            1.000000           0.727143   \n",
       "7           0.937277            1.000000           0.912857   \n",
       "8           0.920884            0.998212           0.898571   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            1.000000           0.712241            1.000000      0.336469   \n",
       "1            0.967500           0.914102            0.967892      0.080747   \n",
       "2            0.890000           0.872584            0.893329      0.378510   \n",
       "3            1.000000           0.732283            1.000000      0.288769   \n",
       "4            0.999643           0.916249            1.000000      0.096395   \n",
       "5            0.959286           0.913386            0.958259      0.165654   \n",
       "6            1.000000           0.732283            1.000000      0.202933   \n",
       "7            1.000000           0.916965            1.000000      0.060910   \n",
       "8            0.997857           0.908375            0.998930      0.198038   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.070002        0.006570         0.000000  \n",
       "1        0.036969        0.005659         0.001298  \n",
       "2        0.060195        0.003419         0.001369  \n",
       "3        0.003356        0.006473         0.000000  \n",
       "4        0.096327        0.010748         0.000292  \n",
       "5        0.009369        0.005613         0.000698  \n",
       "6        0.049788        0.006473         0.000000  \n",
       "7        0.043007        0.010683         0.000000  \n",
       "8        0.095490        0.009137         0.000446  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAGHCAYAAAB1SJU0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10de1e278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can observe that (from higher to lower gamma / left to right):\n",
    "- At very high gamma (0.01), the model is achieving 100% accuracy on the training data, though the test score is quite low (<75%). Thus, the model is overfitting.\n",
    "\n",
    "- At gamma=0.001, the training and test scores are comparable at around C=1, though the model starts to overfit at higher values of C\n",
    "\n",
    "- At gamma=0.0001, the model does not overfit till C=10 but starts showing signs at C=100. Also, the training and test scores are slightly lower than at gamma=0.001.\n",
    "\n",
    "Thus, it seems that the best combination is gamma=0.001 and C=1 (the plot in the middle), which gives the highest test accuracy (~92%) while avoiding overfitting.\n",
    "\n",
    "Let's now build the final model and see the performance on test data.\n",
    "\n",
    "### Final Model\n",
    "\n",
    "Let's now build the final model with chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal hyperparameters\n",
    "best_C = 1\n",
    "best_gamma = 0.001\n",
    "\n",
    "# model\n",
    "svm_final = svm.SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "\n",
    "# fit\n",
    "svm_final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = svm_final.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924973544974 \n",
      "\n",
      "[[3587    0   10   10    5   15   50   12   25    1]\n",
      " [   0 4108   14   16    5    3    6   18   10    5]\n",
      " [  24   23 3407   65   44    5   36  123   54    9]\n",
      " [   4   21   86 3502    5   89   11   73   76   33]\n",
      " [   3   11   36    7 3450   13   23   43    6  110]\n",
      " [  20   29   14  114   18 3020   79   53   36   35]\n",
      " [  31   12   11    1   14   34 3521   44   25    0]\n",
      " [   4   28   27    8   36    7    1 3739    7   97]\n",
      " [  14   59   32   80   22   97   25   44 3251   41]\n",
      " [  23   13   13   50   98    7    0  176   19 3379]]\n"
     ]
    }
   ],
   "source": [
    "# evaluation: CM \n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "\n",
    "# measure accuracy\n",
    "test_accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "\n",
    "print(test_accuracy, \"\\n\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The final accuracy on test data is approx. 92%. Note that this can be significantly increased by using the entire training data of 42,000 images (we have used just 10% of that!). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
